---
layout: about
title: about
permalink: /
nav: true
nav_order: 1
subtitle: Machine Learning PhD Student, UC San Diego

profile:
  align: right
  image: portrait2.png
  image_circular: false
  more_info: >
    <p>Computer Science and Engineering</p>
    <p>UC San Diego</p>
    <p>dbeaglehole@ucsd.edu</p>

selected_papers: true
social: true

announcements:
  enabled: true
  scrollable: true
  limit: 5

latest_posts:
  enabled: true
  scrollable: true
  limit: 3
---

Hello! I am a PhD student in the CSE department at UC San Diego in the [machine learning](https://datascience.ucsd.edu/research/faculty-research-areas/artificial-intelligence-and-machine-learning/) and [theory](https://cstheory.ucsd.edu/home.html) groups. I am very fortunate to be advised by Professor [Mikhail Belkin](http://misha.belkin-wang.org/). Prior to my PhD, I completed an MS in computer science at Columbia University, where I researched under the excellent mentorship of Professor [Alexandr Andoni](http://www.cs.columbia.edu/~andoni/).

I was previously a Student Researcher at Google DeepMind working on feature learning and an ML Research intern at Goldman Sachs. I am supported by the [ARCS Foundation Fellowship](https://san-diego.arcsfoundation.org).

Broadly, I am excited about developing conceptually-driven machine learning and algorithmic methods. I am especially interested in:

1. Feature/representation learning 
2. Deep learning (theory + applications)
3. Steering and monitoring LLMs
4. Tabular/scientific data

Feel free to reach out via email: `dbeaglehole@ucsd.edu`.

_\* denotes equal contribution._

### Preprints

1. [Toward universal steering and monitoring of AI models](https://arxiv.org/abs/2502.03708)  \
   Daniel Beaglehole\*, Adityanarayanan Radhakrishnan\*, Enric Boix-Adserà, Mikhail Belkin
2. [Mechanism of feature learning in convolutional neural networks](https://arxiv.org/pdf/2309.00570v1.pdf)  \
   Daniel Beaglehole\*, Adityanarayanan Radhakrishnan\*, Parthe Pandit, Mikhail Belkin
3. [Mechanism of feature learning in deep fully connected networks and kernel machines that recursively learn features](https://arxiv.org/abs/2212.13881)  \
   Adityanarayanan Radhakrishnan\*, Daniel Beaglehole\*, Parthe Pandit, Mikhail Belkin  \
   [(twitter link)](https://twitter.com/dbeagleholeCS/status/1627819164906975232?s=20)
4. [CAPYBARA: A Generalizable Framework for Predicting Serological Measurements Across Human Cohorts](https://www.medrxiv.org/content/10.1101/2025.07.07.25331040v1)  \
   Sierra Orsinelli-Rivers, Daniel Beaglehole, Tal Einav
5. [Fast, optimal, and dynamic electoral campaign budgeting by a generalized Colonel Blotto game](https://arxiv.org/abs/2406.15714)  \
   Thomas Valles, Daniel Beaglehole

### Publications

1. [Mechanism for feature learning in neural networks and backpropagation-free machine learning models](https://www.science.org/doi/10.1126/science.adi5639)  \
   Adityanarayanan Radhakrishnan\*, Daniel Beaglehole\*, Parthe Pandit, Mikhail Belkin  \
   _Science_
2. [Average gradient outer product as a mechanism for deep neural collapse](https://arxiv.org/abs/2402.13728)  \
   Daniel Beaglehole\*, Peter Súkeník\*, Marco Mondelli, Mikhail Belkin  \
   _Conference on Neural Information Processing Systems (NeurIPS 2024)_
3. [Feature learning as alignment: a structural property of gradient descent in non-linear neural networks](https://arxiv.org/abs/2402.05271)  \
   Daniel Beaglehole, Ioannis Mitliagkas, Atish Agarwala  \
   _Transactions on Machine Learning Research (TMLR)_  \
   _Workshop on High-dimensional Learning Dynamics (HiLD) @ ICML 2024_
4. [Emergence in non-neural models: grokking modular arithmetic via average gradient outer product](https://arxiv.org/abs/2407.20199)  \
   Neil Mallinar, Daniel Beaglehole, Libin Zhu, Adityanarayanan Radhakrishnan, Parthe Pandit, Mikhail Belkin  \
   _International Conference on Machine Learning (ICML 2025) <span style="color: red;">(Oral, Top 1%)</span>_  \
   _Mathematics of Modern Machine Learning (M3L) @ NeurIPS 2024_
5. [On the Inconsistency of Kernel Ridgeless Regression in Fixed Dimensions](https://arxiv.org/abs/2205.13525)  \
   Daniel Beaglehole, Mikhail Belkin, Parthe Pandit  \
   _SIAM Journal on Mathematics of Data Science (SIMODS)_  \
   _Conference on the Mathematical Theory of Deep Neural Networks (DeepMath 2022)_
6. [Sampling Equilibria: Fast No-Regret Learning in Structured Games](https://arxiv.org/abs/2201.10758)  \
   Daniel Beaglehole\*, Max Hopkins\*, Daniel Kane\*, Sihan Liu\*, Shachar Lovett\*  \
   _Symposium on Discrete Algorithms (SODA 2023)_  \
   This began as an earlier version: [An Efficient Approximation Algorithm for the Colonel Blotto Game](https://arxiv.org/abs/2201.10758v6) — Daniel Beaglehole
7. [Learning to Hash Robustly, Guaranteed](https://arxiv.org/abs/2108.05433)  \
   Alexandr Andoni\*, Daniel Beaglehole\*  \
   _International Conference on Machine Learning (ICML 2022)_  \
   [(twitter link)](https://twitter.com/thomasahle/status/1428749917384761346)

## Presentations

1. Google Brain: "Feature learning in neural networks and kernel machines that recursively learn features" (03/2023)
2. Yale University: Inference, Information, and Decision Systems Group — "Feature learning in neural networks and kernel machines that recursively learn features" (03/2023)
3. UC San Diego Theory Seminar: "Learning to Hash Robustly, Guaranteed" (10/2021)
4. Goldman Sachs Data Science and Machine Learning paper club: "Learning to Hash Robustly, Guaranteed" (07/2021)
5. Goldman Sachs Summer internship final presentation: "Predictive Clustering Time Series for Finance" (08/2021)
